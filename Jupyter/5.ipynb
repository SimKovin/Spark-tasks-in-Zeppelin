{
  "metadata": {
    "name": "5",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%pyspark\n\nrdd \u003d sc.parallelize([(1,2), (3,4), (3,6), (4,5), (3, 4), (1, 5), (4, 1)])\n\nrdd.groupByKey().collect()\n\nrdd \\\n    .groupByKey() \\\n    .map(lambda x:(x[0], sum(x[1])) ) \\\n    .collect()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nlines \u003d sc.parallelize([\n    \"a ab abc\",\n    \"a ac abc\",\n    \"b b ab abc\"\n    ])\n\ncounts \u003d lines.flatMap(lambda x: x.split(\u0027 \u0027)) \\\n    .groupBy(lambda x: x) \\\n    .mapValues(len)\n\noutput \u003d counts.collect()\n\nfor (word, count) in output:\n    print(\"%s: %i\" % (word, count))"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nlines.flatMap(lambda x: x.split(\u0027 \u0027)) \\\n    .countByValue() \\\n    .items()"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nlines \u003d sc.parallelize([\n    \"a ab abc\",\n    \"a ac abc\",\n    \"b b ab abc\"\n    ])\n\ncounts \u003d lines.flatMap(lambda x: x.split(\u0027 \u0027)) \\\n    #.sc.parallelize(counts.countByValue().items())\n\n# дополнить код, чтобы получился rdd из пар (слово, частота)\n\noutput \u003d sc.parallelize(counts.countByValue().items()).collect()\n\nfor (word, count) in output:\n    print(\"%s: %i\" % (word, count))"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}