
{
  "metadata": {
    "name": "4",
    "kernelspec": {
        "display_name": "Python 3.8.0 64-bit ('venv_2': virtualenv)",
        "language": "python",
        "name": "venv_2"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "http://10.4.49.41:8088/ui2/#/yarn-apps/apps"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.conf\n\nspark.executor.instances\u003d2\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ".\n.\n.\nНужно скопировать себе эту тетрадку и предоставить доступ к копии на чтение, запись и запуск тетрадки пользователю admin. Параграфы с генерацией данных и созданием семплов запускать не нужно, они оставлены для ознакомления"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "print(\"https://arena-hadoop.inno.tech:18088/proxy/\" + sc.applicationId)"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.mllib.random.RandomRDDs._\nimport java.time.LocalDate\nimport java.time.format.DateTimeFormatter\n\nval dates \u003d (0 to 14).map(LocalDate.of(2020, 11, 1).plusDays(_).format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd\"))).toSeq\n\ndef generateCity(r: Double): String \u003d if (r \u003c 0.9) \"BIG_CITY\" else \"SMALL_CITY_\" + scala.math.round((r - 0.9) * 1000)\n\ndef generateCityUdf \u003d udf(generateCity _)\n\nspark.sql(\"create database hw_4\")\n\nfor(i \u003c- dates) {\n    uniformRDD(sc, 10000000L, 1)\n    .toDF(\"uid\")\n    .withColumn(\"date\", lit(i))\n    .withColumn(\"city\", generateCityUdf($\"uid\"))\n    .selectExpr(\"date\", \" sha2(cast(uid as STRING), 256) event_id\", \"city\")\n    .withColumn(\"skew_key\", when($\"city\" \u003d\u003d\u003d \"BIG_CITY\", lit(\"big_event\")).otherwise($\"event_id\"))\n    .write.mode(\"append\")\n    .partitionBy(\"date\")\n    .saveAsTable(\"hw_4.events_full\")\n}\n"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "spark.table(\"hw_4.events_full\")\n.select(\"event_id\")\n.sample(0.001)\n.repartition(2)\n.write.mode(\"overwrite\")\n.saveAsTable(\"hw_4.sample\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\nspark.table(\"hw_4.sample\")\n.limit(100)\n.coalesce(1)\n.write.mode(\"overwrite\")\n.saveAsTable(\"hw_4.sample_small\")"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n\nspark.table(\"hw_4.events_full\")\n.select(\"event_id\")\n.sample(0.003)\n.repartition(1)\n.write.mode(\"overwrite\")\n.saveAsTable(\"hw_4.sample_big\")"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n\nspark.table(\"hw_4.events_full\")\n.select(\"event_id\")\n.sample(0.015)\n.repartition(1)\n.write.mode(\"overwrite\")\n.saveAsTable(\"hw_4.sample_very_big\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Для упражнений сгрененирован большой набор синтетических данных в таблице hw2.events_full. Из этого набора данных созданы маленькие (относительно исходного набора) таблицы разного размера kotelnikov.sample_[small, big, very_big]. \n\nОтветить на вопросы:\n * какова структура таблиц\n * сколько в них записей \n * сколько места занимают данные\n "
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nspark.read.parquet(\"/apps/hive/warehouse/hw_4.db/events_full\").printSchema()\n\nspark.read.parquet(\"/apps/hive/warehouse/hw_4.db/events_full/date\u003d2020-11-02\").printSchema()\n\nspark.read.parquet(\"/apps/hive/warehouse/hw_4.db/sample\").printSchema()\n\nspark.read.parquet(\"/apps/hive/warehouse/hw_4.db/sample_big\").printSchema()\n\nspark.read.parquet(\"/apps/hive/warehouse/hw_4.db/sample_very_big\").printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nprint(spark.read.parquet(\"/apps/hive/warehouse/hw_4.db/events_full\").count())\n\nprint(spark.read.parquet(\"/apps/hive/warehouse/hw_4.db/events_full/date\u003d2020-11-02\").count())\n\nprint(spark.read.parquet(\"/apps/hive/warehouse/hw_4.db/sample_small\").count())\n\nprint(spark.read.parquet(\"/apps/hive/warehouse/hw_4.db/sample_big\").count())\n\nspark.read.parquet(\"/apps/hive/warehouse/hw_4.db/sample_very_big\").count()"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\n\nhdfs dfs -du -h -s /apps/hive/warehouse/hw_4.db/events_full\n\n\nhdfs dfs -du -h -s /apps/hive/warehouse/hw_4.db/sample_small\n\nhdfs dfs -du -h -s /apps/hive/warehouse/hw_4.db/sample_big\n\nhdfs dfs -du -h -s /apps/hive/warehouse/hw_4.db/sample_very_big"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\n\nhdfs dfs -count -h /apps/hive/warehouse/hw_4.db/sample_small\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ".\n.\n.\n\nПолучить планы запросов для джойна большой таблицы hw2.events_full с каждой из таблиц hw2.sample, hw2.sample_big, hw2.sample_very_big по полю event_id. В каких случаях используется BroadcastHashJoin? \n\nBroadcastHashJoin автоматически выполняется для джойна с таблицами, размером меньше параметра spark.sql.autoBroadcastJoinThreshold. Узнать его значение можно командой spark.conf.get(\"spark.sql.autoBroadcastJoinThreshold\")."
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark \n\nhw_f \u003d spark.read.parquet(\"/apps/hive/warehouse/hw_4.db/events_full\")\nhw_s \u003d spark.read.parquet(\"/apps/hive/warehouse/hw_4.db/sample\")\nhw_b \u003d spark.read.parquet(\"/apps/hive/warehouse/hw_4.db/sample_big\")\nhw_vb \u003d spark.read.parquet(\"/apps/hive/warehouse/hw_4.db/sample_very_big\")\n\ndfs \u003d [hw_s,hw_b,hw_vb]\n\nfor x in dfs:\n    hw_f.join(x,hw_f.event_id\u003d\u003dx.event_id).explain(True)\n    print(\"\\n-----------------\\n\")\n    "
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "BroadcastHashJoin использовался для джойна исходной таблицы с sample и sample_big, а для джойна с sample_very_big использовался SortMergeJoin, так как эта таблица занимает больше места, чем обозначенный порог для BroadcastHashJoin.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\n\nhdfs dfs -du -s /apps/hive/warehouse/hw_4.db/sample_very_big\n"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nspark.conf.get(\"spark.sql.autoBroadcastJoinThreshold\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Выполнить джойны с таблицами  hw2.sample,  hw2.sample_big в отдельных параграфах, чтобы узнать время выполнения запросов (например, вызвать .count() для результатов запросов). Время выполнения параграфа считается автоматически и указывается в нижней части по завершении\n\nЗайти в spark ui (ссылку сгенерировать в следующем папраграфе). Сколько tasks создано на каждую операцию? Почему именно столько? Каков DAG вычислений?  "
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nhw_f.join(hw_s,\"event_id\").count()\n\n# запрос выполнялся 53 секунды"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nhw_f.join(hw_b,\"event_id\").count()\n\n# запрос выполнялся 39 секунд"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(\"http://10.4.49.41:8088/proxy/\" + sc.applicationId + \"/jobs/\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "На операцию было создано 76 tasks. Количество тасок зависит от кол-ва и размеров блоков. Также может зависить от кол-ва партиций, экзекьюторов и используемых ядер. "
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "На операцию было создано 68 tasks. Размер входных данных 7.6 gb. На каждую таску выделилось по 144,5 mb. Соответственно 144,5 * 68 ≈ 7.6 gb.\n\nDAG выглядит следующим образом:\n![alt text](https://i.ibb.co/R02XH8w/dag2.png)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Оптимизировать джойн с таблицами hw2.sample_big, hw2.sample_very_big с помощью broadcast(df). Выполнить запрос, посмотреть в UI, как поменялся план запроса, DAG, количество тасков. Второй запрос не выполнится "
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfrom pyspark.sql.functions import broadcast\n\nhw_f.join(broadcast(hw_b),\"event_id\")"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nhw_f.join(broadcast(hw_b),\"event_id\").count()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Вызывая, например, функцию count(), к джойну с и без broadcast, я не вижу разницы в spark ui..."
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nhw_f.join(broadcast(hw_vb),\"event_id\").show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Отключить автоматический броадкаст командой spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\"). Сделать джойн с семплом hw_4.sample, сравнить время выполнения запроса.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n\nspark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\n\nhw_f.join(hw_s,\"event_id\").count()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Запрос с отключенным автоматическим бродкастом выполняется в разы дольше и происходит spill."
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"26214400\")"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "spark.sql(\"clear cache\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n \n \n\nВ процессе обработки данных может возникнуть перекос объёма партиций по количеству данных (data skew). В таком случае время выполнения запроса может существенно увеличиться, так как данные распределятся по исполнителям неравномерно. В следующем параграфе происходит инициализация датафрейма, этот параграф нужно выполнить, изменять код нельзя. В задании нужно работать с инициализированным датафреймом.\n\nДатафрейм разделен на 30 партиций по ключу city, который имеет сильно  неравномерное распределение."
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark \nfrom pyspark.sql.functions import col\n\nskew_df \u003d spark.table(\"hw_4.events_full\")\\\n.where(\"date \u003d \u00272020-11-02\u0027\")\\\n.repartition(30, col(\"city\"))\\\n.cache()\n\nskew_df.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nsc.applicationId"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ".\n.\n.\n\nПосчитать количество event_count различных событий event_id , содержащихся в skew_df с группировкой по городам. Результат упорядочить по event_count.\n\nВ spark ui в разделе jobs выбрать последнюю, в ней зайти в stage, состоящую из 30 тасков (из такого количества партиций состоит skew_df). На странице стейджа нажать кнопку Event Timeline и увидеть время выполнения тасков по экзекьюторам. Одному из них выпала партиция с существенно большим количеством данных. Остальные экзекьюторы в это время бездействуют -- это и является проблемой, которую предлагается решить далее."
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nimport pyspark.sql.functions as f\n\n#skew_df.groupBy(\"city\").count().show()\nskew_df.groupBy(\"city\").agg(f.count(\"event_id\").alias(\"event_count\")).orderBy(\"event_count\",ascending\u003dFalse).show(40)\n\n#skew_df.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "![alt text](https://i.ibb.co/mBg6LcL/Screenshot-4.png)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ".\n.\n.\n\nодин из способов решения проблемы агрегации по неравномерно распределенному ключу является предварительное перемешивание данных. Его можно сделать с помощью метода repartition(p_num), где p_num -- количество партиций, на которые будет перемешан исходный датафрейм"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nskew_df2 \u003d skew_df.repartition(40)\n\nskew_df2.groupBy(\"city\").agg(f.count(\"event_id\").alias(\"event_count\")).orderBy(\"event_count\").show()\n\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ".\n.\n.\nДругой способ исправить неравномерность по ключу -- создание синтетического ключа с равномерным распределением. В нашем случае неравномерность исходит от единственного значения city\u003d\u0027BIG_CITY\u0027, которое часто повторяется в данных и при группировке попадает к одному экзекьютору. В таком случае лучше провести группировку в два этапа по синтетическому ключу CITY_SALT, который принимает значение BIG_CITY_rand (rand -- случайное целое число) для популярного значения BIG_CITY и CITY для остальных значений. На втором этапе восстанавливаем значения CITY и проводим повторную агрегацию, которая не занимает времени, потому что проводится по существенно меньшего размера данным. \n\nТакая же техника применима и к джойнам по неравномерному ключу, см, например https://itnext.io/handling-data-skew-in-apache-spark-9f56343e58e8\n\nЧто нужно реализовать:\n* добавить синтетический ключ\n* группировка по синтетическому ключу\n* восстановление исходного значения\n* группировка по исходной колонке "
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nsalt \u003d f.expr(\"\"\"pmod(round(rand() * 100, 0), 30)\"\"\").cast(\"integer\")\n#salt \u003d f.expr(\"\"\"pmod(round(rand() * 100, 0), 30)\"\"\").cast(\"integer\")\n\n#concat($\"state_id\", lit(\"_\"), $\"salt\"))\n\nsalted \u003d skew_df.withColumn(\"salt\", salt)\n\nsalted.show()\n\nsalted_agg_df \u003d salted.groupBy(f.col(\"city\"), f.col(\"salt\")).agg(f.count(\"*\").alias(\"count\")) \\\n    .orderBy(f.col(\"count\").asc())\n    \nsalted_agg_df.show(20, False)\n\nagg_df \u003d salted_agg_df \\\n    .groupBy(f.col(\"city\")).agg(f.sum(\"count\").alias(\"final_sum\")) \\\n    .orderBy(f.col(\"final_sum\").desc())\n    \nagg_df.show(20, False)   \n#salted.select(f.col(\"type\"), f.col(\"ident\"), f.col(\"salt\")).sample(0.1).show(20, False)"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfrom pyspark.sql.functions import col, lit, when\n\n#salted_agg_df\n#concat(col(“city_id”), lit(“_”), col(“salt”)\n#salted_agg_df.withColumn(\"city_salt\", f.concat(col(\"city\"), lit(\"_\"), col(\"salt\"))).show()\nsalted_agg_df2 \u003d salted_agg_df.withColumn(\"city_salt\", when(col(\"city\").rlike(\"^BIG\"), f.concat(col(\"city\"), lit(\"_\"), col(\"salt\"))).otherwise(\"CITY\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nagg_df \u003d salted_agg_df2 \\\n    .groupBy(f.col(\"city_salt\")).agg(f.sum(\"count\").alias(\"final_sum\")) \\\n    .orderBy(f.col(\"final_sum\").desc())\n    \nagg_df.show(40, False)  "
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "#### Итого, получаем датафрейм с нормальным распределением значений городов:\n"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndfs \u003d salted_agg_df2.withColumn(\"s\", when(salted_agg_df2.city_salt \u003d\u003d \"CITY\", salted_agg_df2.city).otherwise(salted_agg_df2.city_salt))\n\ndfs.groupBy(f.col(\"s\")).agg(f.sum(\"count\").alias(\"final_sum\")) \\\n    .orderBy(f.col(\"final_sum\").desc()).show()\n\n#df2 \u003d df.withColumn(\"new_gender\", when(df.gender \u003d\u003d \"M\",\"Male\")\n #                                .when(df.gender \u003d\u003d \"F\",\"Female\")\n  #                               .when(df.gender.isNull() ,\"\")\n   #                              .otherwise(df.gender))"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n# пробовал через sql выражение, не получилось\n\nfrom pyspark.sql.functions import expr\n\nskew_df.withColumn(\"Name\",expr(\"CASE WHEN city \u003d \u0027SMALL%\u0027 THEN \u0027CITY\u0027\")).show(truncate\u003dFalse)\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "spark.stop"
    }
  ]
}
