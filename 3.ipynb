{
  "metadata": {
    "name": "3",
    "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('venv_2': virtualenv)",
   "language": "python",
   "name": "venv_2"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# ДЗ 3\n срок -- 6 ноября 18:00\n \n "
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nimport pyspark.sql.functions as f\n\nevents_df \u003d spark.table(\"market.events\")\n\n\nevents_df.show(100)"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf \u003d events_df \\\n.where(\"brand\u003d\u0027apple\u0027\") \\\n.where(\"event_type\u003d\u0027purchase\u0027\")\n\ndf \\\n.select(f.count(\"brand\") \\\n.alias(\"Apple\")) \\\n.show()\n\nevents_df \\\n.where(\"event_type\u003d\u0027purchase\u0027\") \\\n.filter(~df.brand.isin(\"apple\")) \\\n.agg(f.count(\"*\") \\\n.alias(\"Non-apple\")) \\\n.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nz.show(\n    events_df \\\n    .where(\"event_type\u003d\u0027purchase\u0027\") \\\n    .withColumn(\"date\", f.date_trunc(\u0027hour\u0027, \"event_time\")) \\\n    .groupby(\"date\").agg(f.sum(\"price\").alias(\"income\"),f.count(\"price\").alias(\"purchases\")) \\\n    .orderBy(\"date\")\n)"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n\n# to_timestamp, date_trunc, hour\n\nz.show(\n    events_df \\\n    .where(\"event_type\u003d\u0027purchase\u0027\") \\\n    .withColumn(\"time\", f.date_trunc(\u0027hour\u0027, \"event_time\")) \\\n    .groupBy(\"time\").count() \\\n    .withColumn(\"hour\", f.hour(\"time\")) \\\n    .groupby(\"hour\").avg(\"count\") \\\n    .orderBy(\"hour\")\n)"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n# to_timestamp, date_trunc, hour\n\nz.show(\n    events_df \\\n    .where(\"event_type\u003d\u0027view\u0027\") \\\n    .withColumn(\"time\", f.date_trunc(\u0027hour\u0027, \"event_time\")) \\\n    .groupBy(\"time\").count() \\\n    .withColumn(\"hour\", f.hour(\"time\")) \\\n    .groupby(\"hour\").avg(\"count\") \\\n    .orderBy(\"hour\")\n)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}
